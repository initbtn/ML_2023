{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]]\n",
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data1 = [[73., 80., 75.],\n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.],\n",
    "          [96., 98., 100.],\n",
    "          [73., 66., 70.]]\n",
    "t_data1 = [[152.],\n",
    "          [185.],\n",
    "          [180.],\n",
    "          [196.],\n",
    "          [142.]]\n",
    "\n",
    "x_data=np.array(x_data1)\n",
    "t_data=np.array(t_data1)\n",
    "print(x_data)\n",
    "print(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36369152]\n",
      " [0.83541639]\n",
      " [0.52193577]] [0.10665271]\n"
     ]
    }
   ],
   "source": [
    "w=np.random.rand(3,1)\n",
    "b=np.random.rand(1)\n",
    "print(w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y=np.dot(x,w)+b\n",
    "    return (np.sum((t-y)**2))/(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x=1e-4\n",
    "    grad=np.zeros_like(x)\n",
    "\n",
    "    it=np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        tmp_val=x[idx]\n",
    "        \n",
    "        x[idx]=float(tmp_val)+delta_x\n",
    "        fx1=f(x) # f(x+delta_x)\n",
    "\n",
    "        x[idx]=float(tmp_val)-delta_x\n",
    "        fx2=f(x) # f(x-delta_x)\n",
    "\n",
    "        grad[idx]=(fx1-fx2)/(2*delta_x)\n",
    "\n",
    "        x[idx]=tmp_val\n",
    "        it.iternext()\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    y=np.dot(x, w)+b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value= 0.24184189475022774 Initial w= [[0.90530161]\n",
      " [0.46658786]\n",
      " [0.63771784]] b= [0.12426864]\n",
      "step= 0 error value= 0.24184136747505874 w= [[0.90530218]\n",
      " [0.46658772]\n",
      " [0.63771742]] b= [0.12426873]\n",
      "step= 400 error value= 0.2416312812957604 w= [[0.90552882]\n",
      " [0.46653024]\n",
      " [0.63754973]] b= [0.12430406]\n",
      "step= 800 error value= 0.2414228189461653 w= [[0.90575428]\n",
      " [0.46647403]\n",
      " [0.63738197]] b= [0.12433935]\n",
      "step= 1200 error value= 0.24121595117979372 w= [[0.90597858]\n",
      " [0.46641905]\n",
      " [0.63721413]] b= [0.12437461]\n",
      "step= 1600 error value= 0.24101064936656522 w= [[0.90620174]\n",
      " [0.46636529]\n",
      " [0.63704622]] b= [0.12440985]\n",
      "step= 2000 error value= 0.2408068854794861 w= [[0.90642375]\n",
      " [0.46631275]\n",
      " [0.63687824]] b= [0.12444505]\n",
      "step= 2400 error value= 0.24060463208184854 w= [[0.90664463]\n",
      " [0.46626141]\n",
      " [0.6367102 ]] b= [0.12448022]\n",
      "step= 2800 error value= 0.24040386231448121 w= [[0.90686439]\n",
      " [0.46621125]\n",
      " [0.63654209]] b= [0.12451537]\n",
      "step= 3200 error value= 0.24020454988346757 w= [[0.90708305]\n",
      " [0.46616226]\n",
      " [0.63637392]] b= [0.12455048]\n",
      "step= 3600 error value= 0.24000666904804188 w= [[0.90730061]\n",
      " [0.46611443]\n",
      " [0.63620569]] b= [0.12458556]\n",
      "step= 4000 error value= 0.23981019460865038 w= [[0.90751709]\n",
      " [0.46606774]\n",
      " [0.63603741]] b= [0.12462061]\n",
      "step= 4400 error value= 0.23961510189554064 w= [[0.90773249]\n",
      " [0.46602219]\n",
      " [0.63586907]] b= [0.12465564]\n",
      "step= 4800 error value= 0.23942136675727488 w= [[0.90794682]\n",
      " [0.46597775]\n",
      " [0.63570068]] b= [0.12469063]\n",
      "step= 5200 error value= 0.23922896554966208 w= [[0.9081601 ]\n",
      " [0.46593442]\n",
      " [0.63553223]] b= [0.12472559]\n",
      "step= 5600 error value= 0.2390378751249719 w= [[0.90837234]\n",
      " [0.46589218]\n",
      " [0.63536375]] b= [0.12476053]\n",
      "step= 6000 error value= 0.23884807282120812 w= [[0.90858354]\n",
      " [0.46585103]\n",
      " [0.63519521]] b= [0.12479543]\n",
      "step= 6400 error value= 0.2386595364518252 w= [[0.90879372]\n",
      " [0.46581094]\n",
      " [0.63502664]] b= [0.12483031]\n",
      "step= 6800 error value= 0.2384722442954627 w= [[0.90900288]\n",
      " [0.46577191]\n",
      " [0.63485803]] b= [0.12486516]\n",
      "step= 7200 error value= 0.23828617508599756 w= [[0.90921103]\n",
      " [0.46573393]\n",
      " [0.63468937]] b= [0.12489998]\n",
      "step= 7600 error value= 0.2381013080028942 w= [[0.90941819]\n",
      " [0.46569697]\n",
      " [0.63452068]] b= [0.12493476]\n",
      "step= 8000 error value= 0.23791762266153577 w= [[0.90962437]\n",
      " [0.46566104]\n",
      " [0.63435196]] b= [0.12496952]\n",
      "step= 8400 error value= 0.23773509910402396 w= [[0.90982957]\n",
      " [0.46562612]\n",
      " [0.63418321]] b= [0.12500426]\n",
      "step= 8800 error value= 0.23755371778993148 w= [[0.9100338 ]\n",
      " [0.4655922 ]\n",
      " [0.63401443]] b= [0.12503896]\n",
      "step= 9200 error value= 0.23737345958744874 w= [[0.91023707]\n",
      " [0.46555926]\n",
      " [0.63384562]] b= [0.12507363]\n",
      "step= 9600 error value= 0.23719430576466535 w= [[0.91043939]\n",
      " [0.4655273 ]\n",
      " [0.63367678]] b= [0.12510828]\n",
      "step= 10000 error value= 0.2370162379809165 w= [[0.91064078]\n",
      " [0.4654963 ]\n",
      " [0.63350793]] b= [0.12514289]\n",
      "step= 10400 error value= 0.23683923827849296 w= [[0.91084123]\n",
      " [0.46546626]\n",
      " [0.63333905]] b= [0.12517748]\n",
      "step= 10800 error value= 0.23666328907440165 w= [[0.91104076]\n",
      " [0.46543716]\n",
      " [0.63317015]] b= [0.12521204]\n",
      "step= 11200 error value= 0.23648837315239205 w= [[0.91123938]\n",
      " [0.46540899]\n",
      " [0.63300124]] b= [0.12524657]\n",
      "step= 11600 error value= 0.2363144736551309 w= [[0.91143709]\n",
      " [0.46538174]\n",
      " [0.63283231]] b= [0.12528108]\n",
      "step= 12000 error value= 0.2361415740763896 w= [[0.91163391]\n",
      " [0.4653554 ]\n",
      " [0.63266337]] b= [0.12531555]\n",
      "step= 12400 error value= 0.23596965825374344 w= [[0.91182983]\n",
      " [0.46532997]\n",
      " [0.63249442]] b= [0.12535]\n",
      "step= 12800 error value= 0.23579871036102046 w= [[0.91202488]\n",
      " [0.46530542]\n",
      " [0.63232546]] b= [0.12538442]\n",
      "step= 13200 error value= 0.2356287149012602 w= [[0.91221906]\n",
      " [0.46528175]\n",
      " [0.63215649]] b= [0.12541882]\n",
      "step= 13600 error value= 0.23545965669958474 w= [[0.91241238]\n",
      " [0.46525895]\n",
      " [0.63198752]] b= [0.12545318]\n",
      "step= 14000 error value= 0.23529152089634278 w= [[0.91260484]\n",
      " [0.46523701]\n",
      " [0.63181854]] b= [0.12548752]\n",
      "step= 14400 error value= 0.23512429294039294 w= [[0.91279645]\n",
      " [0.46521593]\n",
      " [0.63164956]] b= [0.12552183]\n",
      "step= 14800 error value= 0.23495795858243856 w= [[0.91298722]\n",
      " [0.46519568]\n",
      " [0.63148058]] b= [0.12555611]\n",
      "step= 15200 error value= 0.2347925038686623 w= [[0.91317717]\n",
      " [0.46517626]\n",
      " [0.6313116 ]] b= [0.12559036]\n",
      "step= 15600 error value= 0.23462791513433756 w= [[0.91336629]\n",
      " [0.46515766]\n",
      " [0.63114263]] b= [0.12562459]\n",
      "step= 16000 error value= 0.2344641789976881 w= [[0.91355459]\n",
      " [0.46513987]\n",
      " [0.63097366]] b= [0.12565879]\n",
      "step= 16400 error value= 0.23430128235383868 w= [[0.91374209]\n",
      " [0.46512289]\n",
      " [0.6308047 ]] b= [0.12569296]\n",
      "step= 16800 error value= 0.23413921236886015 w= [[0.91392878]\n",
      " [0.4651067 ]\n",
      " [0.63063575]] b= [0.12572711]\n",
      "step= 17200 error value= 0.23397795647404288 w= [[0.91411468]\n",
      " [0.46509129]\n",
      " [0.63046681]] b= [0.12576123]\n",
      "step= 17600 error value= 0.23381750236018015 w= [[0.9142998 ]\n",
      " [0.46507665]\n",
      " [0.63029788]] b= [0.12579532]\n",
      "step= 18000 error value= 0.23365783797203493 w= [[0.91448414]\n",
      " [0.46506278]\n",
      " [0.63012896]] b= [0.12582939]\n",
      "step= 18400 error value= 0.23349895150288807 w= [[0.91466771]\n",
      " [0.46504967]\n",
      " [0.62996006]] b= [0.12586343]\n",
      "step= 18800 error value= 0.2333408313892807 w= [[0.91485051]\n",
      " [0.46503731]\n",
      " [0.62979118]] b= [0.12589744]\n",
      "step= 19200 error value= 0.23318346630581205 w= [[0.91503255]\n",
      " [0.46502568]\n",
      " [0.62962232]] b= [0.12593142]\n",
      "step= 19600 error value= 0.23302684515998523 w= [[0.91521385]\n",
      " [0.46501479]\n",
      " [0.62945347]] b= [0.12596538]\n",
      "step= 20000 error value= 0.2328709570873185 w= [[0.9153944 ]\n",
      " [0.46500462]\n",
      " [0.62928465]] b= [0.12599931]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-6\n",
    "\n",
    "f=lambda x: loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value=\", loss_func(x_data, t_data), \"Initial w=\", w, \"b=\",b)\n",
    "\n",
    "for step in range(20001):\n",
    "    w-=learning_rate*numerical_derivative(f, w)\n",
    "    b-=learning_rate*numerical_derivative(f, b)\n",
    "\n",
    "    if step % 400==0:\n",
    "        print(\"step=\", step, \"error value=\", loss_func(x_data, t_data), \"w=\",w, \"b=\",b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
