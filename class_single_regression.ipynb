{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "x_data=torch.FloatTensor([[1],[2],[3],[4],[5]])\n",
    "t_data=torch.FloatTensor([[3],[5],[7],[9],[11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(1,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4694], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "model=LinearRegressionModel()\n",
    "print(list(model.parameters()))\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Cost: 1.2523742043413222e-09\n",
      "Epoch: 400 Cost: 7.644303245957218e-11\n",
      "Epoch: 800 Cost: 7.644303245957218e-11\n",
      "Epoch: 1200 Cost: 7.644303245957218e-11\n",
      "Epoch: 1600 Cost: 7.644303245957218e-11\n"
     ]
    }
   ],
   "source": [
    "nb_epochs=2000\n",
    "for epoch in range(nb_epochs):\n",
    "    prediction=model(x_data)\n",
    "    cost=F.mse_loss(prediction,t_data)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%400==0:\n",
    "        print('Epoch:',epoch, 'Cost:', cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21.0000]], grad_fn=<AddmmBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[2.0000]], requires_grad=True), Parameter containing:\n",
      "tensor([1.0000], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "new_data=torch.FloatTensor([[10]])\n",
    "y_pred=model(new_data)\n",
    "print(y_pred)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data=torch.FloatTensor([[73., 80., 75.],\n",
    "            [93., 88., 93.],\n",
    "            [89., 91., 90.],\n",
    "            [96., 98., 100.],\n",
    "            [73., 66., 70.]])\n",
    "t1_data=torch.FloatTensor([[152.],[185.],[180.],[196.],[142.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(3,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0421, -0.0520,  0.0837]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0023], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "model1=MultiLinearRegressionModel()\n",
    "print(list(model1.parameters()))\n",
    "optimizer1=optim.SGD(model1.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Cost: 29938.337890625\n",
      "Epoch: 400 Cost: 1.4944742918014526\n",
      "Epoch: 800 Cost: 1.471176266670227\n",
      "Epoch: 1200 Cost: 1.4483835697174072\n",
      "Epoch: 1600 Cost: 1.4260575771331787\n",
      "Epoch: 2000 Cost: 1.4042048454284668\n",
      "Epoch: 2400 Cost: 1.3827892541885376\n",
      "Epoch: 2800 Cost: 1.3618205785751343\n",
      "Epoch: 3200 Cost: 1.3413043022155762\n",
      "Epoch: 3600 Cost: 1.3212344646453857\n",
      "Epoch: 4000 Cost: 1.301565408706665\n",
      "Epoch: 4400 Cost: 1.28230619430542\n",
      "Epoch: 4800 Cost: 1.2634353637695312\n",
      "Epoch: 5200 Cost: 1.2449910640716553\n",
      "Epoch: 5600 Cost: 1.2269186973571777\n",
      "Epoch: 6000 Cost: 1.2092150449752808\n",
      "Epoch: 6400 Cost: 1.1919076442718506\n",
      "Epoch: 6800 Cost: 1.17494797706604\n",
      "Epoch: 7200 Cost: 1.1583399772644043\n",
      "Epoch: 7600 Cost: 1.142051100730896\n",
      "Epoch: 8000 Cost: 1.1261521577835083\n",
      "Epoch: 8400 Cost: 1.110554814338684\n",
      "Epoch: 8800 Cost: 1.0952832698822021\n",
      "Epoch: 9200 Cost: 1.0803312063217163\n",
      "Epoch: 9600 Cost: 1.065697193145752\n",
      "Epoch: 10000 Cost: 1.051345944404602\n",
      "Epoch: 10400 Cost: 1.0373204946517944\n",
      "Epoch: 10800 Cost: 1.0235729217529297\n",
      "Epoch: 11200 Cost: 1.0100910663604736\n",
      "Epoch: 11600 Cost: 0.9969331622123718\n",
      "Epoch: 12000 Cost: 0.9840252995491028\n",
      "Epoch: 12400 Cost: 0.9713690876960754\n",
      "Epoch: 12800 Cost: 0.9589784741401672\n",
      "Epoch: 13200 Cost: 0.9468300938606262\n",
      "Epoch: 13600 Cost: 0.9349835515022278\n",
      "Epoch: 14000 Cost: 0.9233454465866089\n",
      "Epoch: 14400 Cost: 0.9119526743888855\n",
      "Epoch: 14800 Cost: 0.900809645652771\n",
      "Epoch: 15200 Cost: 0.8898836970329285\n",
      "Epoch: 15600 Cost: 0.879166305065155\n",
      "Epoch: 16000 Cost: 0.8686949014663696\n",
      "Epoch: 16400 Cost: 0.8584221005439758\n",
      "Epoch: 16800 Cost: 0.8483821749687195\n",
      "Epoch: 17200 Cost: 0.8384952545166016\n",
      "Epoch: 17600 Cost: 0.8288893699645996\n",
      "Epoch: 18000 Cost: 0.8194300532341003\n",
      "Epoch: 18400 Cost: 0.8101667165756226\n",
      "Epoch: 18800 Cost: 0.8011045455932617\n",
      "Epoch: 19200 Cost: 0.7922313809394836\n",
      "Epoch: 19600 Cost: 0.7835025191307068\n",
      "Epoch: 20000 Cost: 0.7749911546707153\n",
      "Epoch: 20400 Cost: 0.7666422128677368\n",
      "Epoch: 20800 Cost: 0.7584587335586548\n",
      "Epoch: 21200 Cost: 0.7504472732543945\n",
      "Epoch: 21600 Cost: 0.7425893545150757\n",
      "Epoch: 22000 Cost: 0.7349100112915039\n",
      "Epoch: 22400 Cost: 0.7273516058921814\n",
      "Epoch: 22800 Cost: 0.7199707627296448\n",
      "Epoch: 23200 Cost: 0.7127516865730286\n",
      "Epoch: 23600 Cost: 0.7056342959403992\n",
      "Epoch: 24000 Cost: 0.6987087726593018\n",
      "Epoch: 24400 Cost: 0.6918758153915405\n",
      "Epoch: 24800 Cost: 0.6852355003356934\n",
      "Epoch: 25200 Cost: 0.6786687970161438\n",
      "Epoch: 25600 Cost: 0.6722976565361023\n",
      "Epoch: 26000 Cost: 0.6659985780715942\n",
      "Epoch: 26400 Cost: 0.6598712801933289\n",
      "Epoch: 26800 Cost: 0.6538490056991577\n",
      "Epoch: 27200 Cost: 0.6479114294052124\n",
      "Epoch: 27600 Cost: 0.6421489715576172\n",
      "Epoch: 28000 Cost: 0.6364624500274658\n",
      "Epoch: 28400 Cost: 0.6309096813201904\n",
      "Epoch: 28800 Cost: 0.6254526376724243\n",
      "Epoch: 29200 Cost: 0.6200979948043823\n",
      "Epoch: 29600 Cost: 0.6148747801780701\n",
      "Epoch: 30000 Cost: 0.6097200512886047\n",
      "Epoch: 30400 Cost: 0.6047185659408569\n",
      "Epoch: 30800 Cost: 0.5997756123542786\n",
      "Epoch: 31200 Cost: 0.594933271408081\n",
      "Epoch: 31600 Cost: 0.5902023315429688\n",
      "Epoch: 32000 Cost: 0.5855578184127808\n",
      "Epoch: 32400 Cost: 0.5809667706489563\n",
      "Epoch: 32800 Cost: 0.5765150785446167\n",
      "Epoch: 33200 Cost: 0.5721257328987122\n",
      "Epoch: 33600 Cost: 0.5678342580795288\n",
      "Epoch: 34000 Cost: 0.5636368989944458\n",
      "Epoch: 34400 Cost: 0.5594893097877502\n",
      "Epoch: 34800 Cost: 0.5554503202438354\n",
      "Epoch: 35200 Cost: 0.5514828562736511\n",
      "Epoch: 35600 Cost: 0.5475805997848511\n",
      "Epoch: 36000 Cost: 0.5437911748886108\n",
      "Epoch: 36400 Cost: 0.5400336980819702\n",
      "Epoch: 36800 Cost: 0.536334216594696\n",
      "Epoch: 37200 Cost: 0.5327569246292114\n",
      "Epoch: 37600 Cost: 0.5292226672172546\n",
      "Epoch: 38000 Cost: 0.5257459878921509\n",
      "Epoch: 38400 Cost: 0.5223289728164673\n",
      "Epoch: 38800 Cost: 0.5190013647079468\n",
      "Epoch: 39200 Cost: 0.5157193541526794\n",
      "Epoch: 39600 Cost: 0.5124964714050293\n",
      "Epoch: 40000 Cost: 0.5093643665313721\n",
      "Epoch: 40400 Cost: 0.5062696933746338\n",
      "Epoch: 40800 Cost: 0.5032222270965576\n",
      "Epoch: 41200 Cost: 0.5002734065055847\n",
      "Epoch: 41600 Cost: 0.49733978509902954\n",
      "Epoch: 42000 Cost: 0.4944654107093811\n",
      "Epoch: 42400 Cost: 0.49166756868362427\n",
      "Epoch: 42800 Cost: 0.4889114797115326\n",
      "Epoch: 43200 Cost: 0.48619168996810913\n",
      "Epoch: 43600 Cost: 0.483523428440094\n",
      "Epoch: 44000 Cost: 0.48092761635780334\n",
      "Epoch: 44400 Cost: 0.4783652722835541\n",
      "Epoch: 44800 Cost: 0.47583723068237305\n",
      "Epoch: 45200 Cost: 0.47334766387939453\n",
      "Epoch: 45600 Cost: 0.47093504667282104\n",
      "Epoch: 46000 Cost: 0.4685521125793457\n",
      "Epoch: 46400 Cost: 0.4661977291107178\n",
      "Epoch: 46800 Cost: 0.46389031410217285\n",
      "Epoch: 47200 Cost: 0.4616459012031555\n",
      "Epoch: 47600 Cost: 0.4594331383705139\n",
      "Epoch: 48000 Cost: 0.4572330415248871\n",
      "Epoch: 48400 Cost: 0.4551011621952057\n",
      "Epoch: 48800 Cost: 0.45301955938339233\n",
      "Epoch: 49200 Cost: 0.4509562849998474\n",
      "Epoch: 49600 Cost: 0.4489213824272156\n",
      "Epoch: 50000 Cost: 0.44694027304649353\n",
      "Epoch: 50400 Cost: 0.4449935853481293\n",
      "Epoch: 50800 Cost: 0.44307976961135864\n",
      "Epoch: 51200 Cost: 0.4411868453025818\n",
      "Epoch: 51600 Cost: 0.4393067955970764\n",
      "Epoch: 52000 Cost: 0.4375065863132477\n",
      "Epoch: 52400 Cost: 0.43573063611984253\n",
      "Epoch: 52800 Cost: 0.4339618682861328\n",
      "Epoch: 53200 Cost: 0.4322219789028168\n",
      "Epoch: 53600 Cost: 0.43049702048301697\n",
      "Epoch: 54000 Cost: 0.42882785201072693\n",
      "Epoch: 54400 Cost: 0.42718714475631714\n",
      "Epoch: 54800 Cost: 0.42557239532470703\n",
      "Epoch: 55200 Cost: 0.4239705502986908\n",
      "Epoch: 55600 Cost: 0.4223783016204834\n",
      "Epoch: 56000 Cost: 0.4208468496799469\n",
      "Epoch: 56400 Cost: 0.41933736205101013\n",
      "Epoch: 56800 Cost: 0.41785305738449097\n",
      "Epoch: 57200 Cost: 0.4163690209388733\n",
      "Epoch: 57600 Cost: 0.414925754070282\n",
      "Epoch: 58000 Cost: 0.41351303458213806\n",
      "Epoch: 58400 Cost: 0.4121214747428894\n",
      "Epoch: 58800 Cost: 0.410745233297348\n",
      "Epoch: 59200 Cost: 0.4093936085700989\n",
      "Epoch: 59600 Cost: 0.40806037187576294\n",
      "Epoch: 60000 Cost: 0.40675634145736694\n",
      "Epoch: 60400 Cost: 0.4054850935935974\n",
      "Epoch: 60800 Cost: 0.40421953797340393\n",
      "Epoch: 61200 Cost: 0.40297308564186096\n",
      "Epoch: 61600 Cost: 0.40172678232192993\n",
      "Epoch: 62000 Cost: 0.4005115032196045\n",
      "Epoch: 62400 Cost: 0.3993408679962158\n",
      "Epoch: 62800 Cost: 0.3981899619102478\n",
      "Epoch: 63200 Cost: 0.39702287316322327\n",
      "Epoch: 63600 Cost: 0.39589112997055054\n",
      "Epoch: 64000 Cost: 0.3947499394416809\n",
      "Epoch: 64400 Cost: 0.3936289846897125\n",
      "Epoch: 64800 Cost: 0.39256492257118225\n",
      "Epoch: 65200 Cost: 0.3915034234523773\n",
      "Epoch: 65600 Cost: 0.39045992493629456\n",
      "Epoch: 66000 Cost: 0.3894140124320984\n",
      "Epoch: 66400 Cost: 0.3883821666240692\n",
      "Epoch: 66800 Cost: 0.38735175132751465\n",
      "Epoch: 67200 Cost: 0.38633081316947937\n",
      "Epoch: 67600 Cost: 0.3853486478328705\n",
      "Epoch: 68000 Cost: 0.3843859136104584\n",
      "Epoch: 68400 Cost: 0.38344234228134155\n",
      "Epoch: 68800 Cost: 0.38249677419662476\n",
      "Epoch: 69200 Cost: 0.3815564513206482\n",
      "Epoch: 69600 Cost: 0.38062646985054016\n",
      "Epoch: 70000 Cost: 0.3797001838684082\n",
      "Epoch: 70400 Cost: 0.3788019120693207\n",
      "Epoch: 70800 Cost: 0.3779263496398926\n",
      "Epoch: 71200 Cost: 0.37706029415130615\n",
      "Epoch: 71600 Cost: 0.37620019912719727\n",
      "Epoch: 72000 Cost: 0.3753517270088196\n",
      "Epoch: 72400 Cost: 0.37450891733169556\n",
      "Epoch: 72800 Cost: 0.3736698031425476\n",
      "Epoch: 73200 Cost: 0.3728557527065277\n",
      "Epoch: 73600 Cost: 0.37204936146736145\n",
      "Epoch: 74000 Cost: 0.37126657366752625\n",
      "Epoch: 74400 Cost: 0.3704889714717865\n",
      "Epoch: 74800 Cost: 0.3697124123573303\n",
      "Epoch: 75200 Cost: 0.36894455552101135\n",
      "Epoch: 75600 Cost: 0.36817649006843567\n",
      "Epoch: 76000 Cost: 0.36743324995040894\n",
      "Epoch: 76400 Cost: 0.3666922152042389\n",
      "Epoch: 76800 Cost: 0.36597397923469543\n",
      "Epoch: 77200 Cost: 0.365263432264328\n",
      "Epoch: 77600 Cost: 0.36456161737442017\n",
      "Epoch: 78000 Cost: 0.36385658383369446\n",
      "Epoch: 78400 Cost: 0.3631581664085388\n",
      "Epoch: 78800 Cost: 0.3624730110168457\n",
      "Epoch: 79200 Cost: 0.36179184913635254\n",
      "Epoch: 79600 Cost: 0.36112427711486816\n",
      "Epoch: 80000 Cost: 0.3604578971862793\n",
      "Epoch: 80400 Cost: 0.35981279611587524\n",
      "Epoch: 80800 Cost: 0.35917338728904724\n",
      "Epoch: 81200 Cost: 0.3585396409034729\n",
      "Epoch: 81600 Cost: 0.3579118847846985\n",
      "Epoch: 82000 Cost: 0.357283353805542\n",
      "Epoch: 82400 Cost: 0.3566618859767914\n",
      "Epoch: 82800 Cost: 0.3560420870780945\n",
      "Epoch: 83200 Cost: 0.35543757677078247\n",
      "Epoch: 83600 Cost: 0.3548412621021271\n",
      "Epoch: 84000 Cost: 0.3542540967464447\n",
      "Epoch: 84400 Cost: 0.35367995500564575\n",
      "Epoch: 84800 Cost: 0.3531027138233185\n",
      "Epoch: 85200 Cost: 0.3525369465351105\n",
      "Epoch: 85600 Cost: 0.35196763277053833\n",
      "Epoch: 86000 Cost: 0.3514065146446228\n",
      "Epoch: 86400 Cost: 0.350838840007782\n",
      "Epoch: 86800 Cost: 0.35027357935905457\n",
      "Epoch: 87200 Cost: 0.34971967339515686\n",
      "Epoch: 87600 Cost: 0.3491712212562561\n",
      "Epoch: 88000 Cost: 0.34864556789398193\n",
      "Epoch: 88400 Cost: 0.34812238812446594\n",
      "Epoch: 88800 Cost: 0.3476065993309021\n",
      "Epoch: 89200 Cost: 0.3470894694328308\n",
      "Epoch: 89600 Cost: 0.346576452255249\n",
      "Epoch: 90000 Cost: 0.34607115387916565\n",
      "Epoch: 90400 Cost: 0.3455578684806824\n",
      "Epoch: 90800 Cost: 0.34505122900009155\n",
      "Epoch: 91200 Cost: 0.3445375859737396\n",
      "Epoch: 91600 Cost: 0.3440418839454651\n",
      "Epoch: 92000 Cost: 0.34353384375572205\n",
      "Epoch: 92400 Cost: 0.3430275022983551\n",
      "Epoch: 92800 Cost: 0.3425362706184387\n",
      "Epoch: 93200 Cost: 0.3420677185058594\n",
      "Epoch: 93600 Cost: 0.3415955901145935\n",
      "Epoch: 94000 Cost: 0.34113574028015137\n",
      "Epoch: 94400 Cost: 0.34067291021347046\n",
      "Epoch: 94800 Cost: 0.34021511673927307\n",
      "Epoch: 95200 Cost: 0.33975914120674133\n",
      "Epoch: 95600 Cost: 0.3392972946166992\n",
      "Epoch: 96000 Cost: 0.3388402462005615\n",
      "Epoch: 96400 Cost: 0.3383849263191223\n",
      "Epoch: 96800 Cost: 0.33793672919273376\n",
      "Epoch: 97200 Cost: 0.3374730944633484\n",
      "Epoch: 97600 Cost: 0.3370215892791748\n",
      "Epoch: 98000 Cost: 0.3365686237812042\n",
      "Epoch: 98400 Cost: 0.33612188696861267\n",
      "Epoch: 98800 Cost: 0.33567115664482117\n",
      "Epoch: 99200 Cost: 0.33526411652565\n",
      "Epoch: 99600 Cost: 0.3348475992679596\n"
     ]
    }
   ],
   "source": [
    "nb1_epochs=100000\n",
    "for epoch in range(nb1_epochs):\n",
    "    prediction=model1(x1_data)\n",
    "    cost=F.mse_loss(prediction, t1_data)\n",
    "\n",
    "    optimizer1.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer1.step()\n",
    "\n",
    "    if epoch%400==0:\n",
    "        print(\"Epoch:\", epoch, \"Cost:\", cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.8652, 0.4444, 0.7031]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2053], requires_grad=True)]\n",
      "tensor([[167.8380]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(list(model1.parameters()))\n",
    "new_data1=torch.FloatTensor([[80,80,90]])\n",
    "y_pred1=model1(new_data1)\n",
    "print(y_pred1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
